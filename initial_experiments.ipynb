{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through these experiments, we want to show two issues in studying interaction between drugs and domains.\n",
    "1. **First problem:** That when a drug interacts with a single-domain protein (with domain X), even if we correctly conclude that it interacts with domain X, It may not interact with another single domain protein that has domain X. This is easy to check using Data. For this, we need some negative interaction data and for that, we can go to affinity data.  \n",
    "2. **Second Problem:** is about multi-domain proteins and that is when a drug is interacting with a multi-domain protein (with domains X and Y), we canâ€™t confidently say if this drug interacts with X or Y or both or either or neither meaning several cases are possible:  \n",
    "    - The drug interacts with protein because it interacts directly with X\n",
    "    - The drug interacts with protein because it interacts directly with Y\n",
    "    - The drug interacts with protein because X and Y are both present\n",
    "    - The drug interacts with protein because either of X or Y are present\n",
    "    - The drug interacts because X and Y are present and they are in certain configuration with respect to each other or other extrinsic properties of the protein besides existence of X and Y.\n",
    "    - The drug interacts for a completely irrelevant reason to existence of X or Y. \n",
    "    \n",
    "There might be some overlap between the problem-1 and problem-2. But conceptually, we can say that first problem arises when trying to go from a drug-domain interaction to drug-protein interaction and the second problem arises when we go in the reverse direction. We want to see if we can quantitatively assess how prevalent these problems are or at least illuminate them as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from positive interactions to negative\n",
    "This means we infer drug-domain interactions from drug interactions of single domain proteins, and then find examples where the same domain occurs in other proteins but doesn't interact with same drugs (we have a negative interaction for it in our dataset). for this, the negative interactions are very important. common drug-target interaction databases only have positive interactions and they assume lack of a pair in the dataset to mean lack of interaction, which is obviously not correct. However there are some researches that also collect negative interaction data like [Coelho2016](https://doi.org/10.1371/journal.pcbi.1005219) where they have used affinity data to extract some negative interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt using Coelho2016 datset\n",
    "This dataset is based on [Coelho2016](https://doi.org/10.1371/journal.pcbi.1005219) paper and contains negative and positive interactions. Negative interactions are extracted from BindingDB and BioLip databases, even though BioLip is questionable as a source of negative interactions because it is extracted from strucutres of drug-target complexes in the PDB, while we are more interested in those based on chemical assays.\n",
    "To use this dataset to search for cases of problem-1, we create a table where for each pair of drug D and proteins P, where the protein is single-domain M, we list all other proteins Q that have the same domain M and divide them into three groups:\n",
    "1. **Pos:** those that there is a positive interaction in the dataset between Q and D\n",
    "1. **Neg:** those that there is a negative interaction in the dataset between Q and D\n",
    "1. **Unk:** those that there is no interaction information in the dataset between Q and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#first we read the dataset and \n",
    "\n",
    "interacts = dict() # for each pair in the dataset (key),  it shows the annotations True/False (interaction/non-interaction) if it exists in the dataset. we basically store all dataset infromation here.\n",
    "uniprot_ids = set() # set of uniprot IDs for the purpose of collecting their pfam domain annotations\n",
    "drugsof= dict() # we want positive interactions for single domain proteins so we store them here to be readily available\n",
    "\n",
    "import pandas\n",
    "for f in [\"drugbank_DTIs_REAL_NEGS.txt\",\"test_data_sc_and_bc.txt\",\"yamanishi_DTIs_REAL_NEGS.txt\"]:\n",
    "    df = pandas.read_csv(\"DTIPred/\"+f, sep = \"\\t\", header = None)\n",
    "    for index , row in df.iterrows():\n",
    "        pid  = row[0]\n",
    "        did  = row[1]\n",
    "        interaction_exist  = row[2]\n",
    "        uniprot_ids.add(pid)\n",
    "#         if (pid,did) in interacts:\n",
    "#             if (interacts[(pid,did)] != interaction_exist):\n",
    "#                 print (\"error repeat\", (pid,did))\n",
    "#         else:\n",
    "        interacts[(pid,did)] = interaction_exist \n",
    "        if interaction_exist == 1:               \n",
    "            if pid in drugsof:\n",
    "                drugsof[pid].append(did)\n",
    "            else:\n",
    "                drugsof[pid] = [did]\n",
    "        \n",
    "with open (\"DTIPred/uniprotids.txt\", \"w\") as pf:\n",
    "    pf.writelines(\"\\n\".join(uniprot_ids))\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here, we read the domain annotations we have downloaded from uniprot.\n",
    "\n",
    "import pandas\n",
    "\n",
    "def extract_items(field):\n",
    "    if \";\" not in field:\n",
    "        return []\n",
    "    else:\n",
    "        spl = field.split(\";\")\n",
    "        for s in spl:\n",
    "            if len(s) <=1:\n",
    "#                 print(s)\n",
    "                spl.remove(s)\n",
    "        return spl\n",
    "\n",
    "proteinswith = dict() #for each domain (pfam ID), this will store the set of proteins (uniprot IDs) that have this domain\n",
    "domainsof  = dict () #for each protein (uniprot ID), this will store the list of domains (pfam IDs) of that protein\n",
    "df = pandas.read_csv(\"DTIPred/uniprotids_annnots.tab\", sep = \"\\t\", converters={i: str for i in range(100)})\n",
    "\n",
    "for index , row in df.iterrows():\n",
    "    domain_field = row [\"Cross-reference (Pfam)\"]\n",
    "    pid = row[\"yourlist:M20210201A94466D2655679D1FD8953E075198DA83D46A3C\"]    \n",
    "    if True: #conditions for considering a protien such as being human protein or being reviewed\n",
    "            domain_list = extract_items(domain_field)\n",
    "            domainsof[pid]= domain_list \n",
    "            for dom  in domain_list:\n",
    "                if dom in proteinswith:\n",
    "                    proteinswith[dom].append(pid)\n",
    "                else:\n",
    "                    proteinswith[dom]= [pid]\n",
    "        \n",
    "    \n",
    "num_domains = {x:len(domainsof[x]) for x in domainsof.keys()}\n",
    "one_domain = [x for x in domainsof.keys() if len(domainsof[x])==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here we do the calculations, meaning we prepare the table consisting of pairs of single domain proteins (P) and interacting drugs (D) the number of proteins falling to each of the three groups and the ID of these proteins are stored in the next columns\n",
    "\n",
    "drug_level_examples = \"onedomain-protein,domain,interacting_drug,num_pos,num_neg,num_unk,pos,neg,unk\\n\"\n",
    "protein_level_exmples  = \"\"\n",
    "\n",
    "\n",
    "for p in one_domain:\n",
    "    m = domainsof[p][0]\n",
    "    Q_set = proteinswith[m].copy()\n",
    "    if p in Q_set:\n",
    "        Q_set.remove(p)        \n",
    "    if p in drugsof:\n",
    "        D_set = drugsof[p]\n",
    "        for d in D_set:\n",
    "            negs = []\n",
    "            pos = []\n",
    "            unk= []\n",
    "            for q in Q_set:\n",
    "                if (q,d) in interacts:\n",
    "                    if interacts[(q,d)]==1:\n",
    "                        pos.append(q)\n",
    "                    else:\n",
    "                        negs.append(q)\n",
    "                else:\n",
    "                    unk.append(q)\n",
    "            row_str= \",\".join ([p,m,d,str(len(pos)),str(len(negs)),str(len(unk)),\";\".join(pos), \";\".join(negs), \";\".join(unk)])+\"\\n\"\n",
    "            drug_level_examples+= row_str\n",
    "            \n",
    "with open(\"result_drug_level.csv\",\"w\") as outf:\n",
    "    outf.writelines(drug_level_examples)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this experiments showed that we couldn't find occurance of the problem-1 with this dataset. This can be due to small number of negative interactions that we have which can be due the the dataset being old. Therefore, we recollect the negative interactions from BindingDB to do this experiment again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second attempt using BindingDB\n",
    "we downloaded the BindingDB in tsv format. There were few issues here. First of all, for affinity, there are several measures here including Ki, Kd, IC50, and EC50. The literature that use affinity to obtain negative interactions don't clarfiy which of these measures they have used except one preprint that says they use Ki or IC50, even though based on a search that I did Kd is the most relevant measure for durg binding to proteins. \n",
    "Another problem is that some of the rows (interactions) in the bindingDB don't have a uniprot ID or have multiple chains. these cases altogether constitute less than 13% of interactions in the dataset. So for now, we ignore them because it makes the life much easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_dataset= False\n",
    "interaction_threshold = 1000\n",
    "noninteraction_threshold = 30000\n",
    "blank_length_threshold = 30\n",
    "bindingdb_path = \"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\"\n",
    "domain_data_dir = \"temp/domain_data/\"\n",
    "pickled_data_path = \"temp/pickled_data/data.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### alternatively we strore them in a pickle and only read them from there later\n",
    "\n",
    "import os\n",
    "import pandas \n",
    "import numpy\n",
    "import pickle\n",
    "import xmltodict\n",
    "from os import path\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "def binarize_field(x,l_threshold,h_threshold):\n",
    "    try:\n",
    "        if type(x) != str:\n",
    "            return \"nonstring\"\n",
    "        else:\n",
    "            x_c = x.replace(\">\",\"\")\n",
    "            x_c = x.replace(\"<\",\"\")\n",
    "            x_C = x.replace(\" \",\"\")\n",
    "            val  = float(x_c)\n",
    "            if val == 0:\n",
    "                return \"zero\"\n",
    "            if val>h_threshold:\n",
    "                val_bin = False\n",
    "            elif val<l_threshold:\n",
    "                val_bin = True\n",
    "            else:\n",
    "                return \"middle\"\n",
    "            if val_bin and (\">\" in x):\n",
    "                return \"invalid\"\n",
    "            if (not val_bin) and (\"<\" in x):\n",
    "                return \"invalid\"\n",
    "            return val_bin\n",
    "    except:\n",
    "        return \"error\"\n",
    "\n",
    "    \n",
    "    \n",
    "def binarize(rows):\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    try:\n",
    "        Ki_col= rows[\"Ki (nM)\"].values \n",
    "        IC50_col= rows[\"IC50 (nM)\"].values\n",
    "    except:\n",
    "        Ki_col= [rows[\"Ki (nM)\"]]\n",
    "        IC50_col= [[\"IC50 (nM)\"]]\n",
    "    for i in range(len(Ki_col)):\n",
    "        bin_Ki = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        bin_IC50 = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        if type (bin_Ki)== bool:\n",
    "            if bin_Ki:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "        if type (bin_IC50)== bool:\n",
    "            if bin_IC50:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "    num_all = num_pos + num_neg\n",
    "    if num_all == 0:\n",
    "        return \"undecided_none\"\n",
    "    if num_neg == 0:\n",
    "        return True\n",
    "    if num_pos == 0:\n",
    "        return False\n",
    "    pos_fraction = float(num_pos)/num_all\n",
    "    neg_fraction = float(num_neg)/num_all\n",
    "    if pos_fraction>0.5:\n",
    "        return True\n",
    "    if neg_fraction>0.5:\n",
    "        return False\n",
    "    return \"undceided_conflict\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binarize_strict(rows):\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    try:\n",
    "        Ki_col= rows[\"Ki (nM)\"].values \n",
    "        IC50_col= rows[\"IC50 (nM)\"].values\n",
    "    except:\n",
    "        Ki_col= [rows[\"Ki (nM)\"]]\n",
    "        IC50_col= [[\"IC50 (nM)\"]]\n",
    "    for i in range(len(Ki_col)):\n",
    "        bin_Ki = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        bin_IC50 = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        if (type (bin_Ki)== bool) and (type (bin_IC50)== bool):\n",
    "            if bin_Ki and bin_IC50:\n",
    "                num_pos+=1\n",
    "            elif (not bin_Ki) and (not bin_IC50):\n",
    "                num_neg+=1            \n",
    "        elif type (bin_Ki)== bool:\n",
    "            if bin_Ki:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "        elif type (bin_IC50)== bool:\n",
    "            if bin_IC50:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "    num_all = num_pos + num_neg\n",
    "    if num_all == 0:\n",
    "        return \"undecided_none\"\n",
    "    if num_neg == 0:\n",
    "        return True\n",
    "    if num_pos == 0:\n",
    "        return False\n",
    "#     pos_fraction = float(num_pos)/num_all\n",
    "#     neg_fraction = float(num_neg)/num_all\n",
    "#     if pos_fraction>0.5:\n",
    "#         return True\n",
    "#     if neg_fraction>0.5:\n",
    "#         return False\n",
    "    return \"undceided_conflict\"\n",
    "\n",
    "class StringConverter(dict):\n",
    "    def __contains__(self, item):\n",
    "        return True\n",
    "    def __getitem__(self, item):\n",
    "        return str\n",
    "    def get(self, default=None):\n",
    "        return str\n",
    "\n",
    "def extract_items(field):\n",
    "    if \";\" not in field:\n",
    "        return []\n",
    "    else:\n",
    "        spl = field.split(\";\")\n",
    "        for s in spl:\n",
    "            if len(s) <=1:\n",
    "    #                 print(s)\n",
    "                spl.remove(s)\n",
    "        return spl\n",
    "\n",
    "\n",
    "def pfam_record_dict(p):\n",
    "    p_path = domain_data_dir + p + \".xml\"\n",
    "    if not path.exists(p_path):\n",
    "        url = \"http://pfam.xfam.org/protein/\"+p+\"?output=xml\"\n",
    "        req = requests.get(url)\n",
    "        with open (domain_data_dir+prot+\".xml\",\"w\") as outf:\n",
    "            outf.writelines(req.text)\n",
    "            \n",
    "    with open(p_path) as pf:\n",
    "        p_dict = xmltodict.parse(pf.read())\n",
    "    return p_dict\n",
    "\n",
    "def get_domains(p):\n",
    "    p_dict = pfam_record_dict(p)\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    domain_list =[]\n",
    "    if type(p_domains) != list:\n",
    "        p_domains =[p_domains]\n",
    "    for dom in p_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        domain_list.append(acc)\n",
    "    return domain_list\n",
    "\n",
    "# def specie_name(p):\n",
    "#     p_dict  = pfam_record_dict(p)\n",
    "#     return p_dict[\"pfam\"][\"entry\"][\"taxonomy\"][\"@species_name\"]\n",
    "\n",
    "\n",
    "def check_single_domain(p):\n",
    "    p_dict = pfam_record_dict(p)\n",
    "    p_seq  = p_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "    p_len  = len (p_seq)\n",
    "    on_domain =[False]*p_len\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    if type(p_domains) != list:\n",
    "        p_domains =[p_domains]\n",
    "    for dom in p_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        # type = dom[\"@type\"]\n",
    "        begin = int(dom[\"location\"][\"@start\"])-1\n",
    "        end = int(dom[\"location\"][\"@end\"])-1\n",
    "        on_domain[begin:end]  = [True] * ((end-begin)+1)\n",
    "    streak = 0 \n",
    "    max_streak = 0\n",
    "    for i in range(p_len):\n",
    "        if on_domain[i]:\n",
    "            streak = 0            \n",
    "        else:\n",
    "            streak += 1\n",
    "            max_streak  = max(streak, max_streak)\n",
    "            \n",
    "    if (max_streak > blank_length_threshold) or (len(p_domains)>1):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "import sys\n",
    "import io\n",
    "binfileexist = os.path.exists(pickled_data_path)\n",
    "\n",
    "if (not binfileexist) or reload_dataset:\n",
    "#     col_names = pandas.read_csv(\"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\", sep = \"\\t\", nrows=0).columns\n",
    "    print (\"Reading Binding DB file...\",end = \"\")\n",
    "\n",
    "    save_stderr = sys.stderr\n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "    df = pandas.read_csv(bindingdb_path, sep = \"\\t\",error_bad_lines=False,converters=StringConverter())\n",
    "    sys.stderr = save_stderr\n",
    "    \n",
    "    single_chain_mask = df[\"Number of Protein Chains in Target (>1 implies a multichain complex)\"]==\"1\"\n",
    "    hasswissprot_mask = numpy.logical_not(df[\"UniProt (SwissProt) Primary ID of Target Chain\"].isna())\n",
    "    haspubchemcid_mask = numpy.logical_not(df[\"PubChem CID\"].isna())\n",
    "    singlechain_idcomplete_mask  = single_chain_mask & hasswissprot_mask & haspubchemcid_mask\n",
    "    easy_df = df.loc[singlechain_idcomplete_mask,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    interaction_idx = dict()\n",
    "    idx = 0 \n",
    "    for index, row in easy_df.iterrows():\n",
    "        idx+=1\n",
    "        print (\"\\r                                                     \\rGrouping rows by drug-protein pairs \"+str(int(idx*100/len(easy_df)))+\"%\",end = \"\")\n",
    "        pid = row[\"UniProt (SwissProt) Primary ID of Target Chain\"]\n",
    "        did = row[\"PubChem CID\"]\n",
    "        if (pid != \"\") and (did != \"\"):\n",
    "            if (pid,did) in interaction_idx:\n",
    "                interaction_idx[(pid,did)].append(index)\n",
    "            else:\n",
    "                interaction_idx[(pid,did)] = [index]\n",
    "            \n",
    "    interact = dict()\n",
    "    drugsof = dict()\n",
    "    idx = 0\n",
    "    included_proteins = set()\n",
    "    for (p,d) in interaction_idx:\n",
    "        idx+=1\n",
    "        print (\"\\r                                                                          \\rBinarizing \"+str(int(idx*100/len(interaction_idx)))+\"%\",end = \"\")\n",
    "        res = binarize_strict(easy_df.loc[interaction_idx[(p,d)],:])\n",
    "        if type(res)== bool:\n",
    "            interact[(p,d)] = res\n",
    "            included_proteins.add(p)\n",
    "            if res:\n",
    "                if p in drugsof:\n",
    "                    drugsof[p].add(d)\n",
    "                else:\n",
    "                    drugsof[p] = {d}\n",
    "\n",
    "    \n",
    "    issingledom = dict()\n",
    "    proteinswith = dict() #for each domain (pfam ID), this will store the set of proteins (uniprot IDs) that have this domain\n",
    "    domainsof  = dict () \n",
    "    included_proteins_with_domain = []\n",
    "    for p in included_proteins:\n",
    "        try:\n",
    "            domain_list=get_domains(p)\n",
    "            domainsof[p]= domain_list\n",
    "            for dom  in domain_list:\n",
    "                if dom in proteinswith:\n",
    "                    proteinswith[dom].add(p)\n",
    "                else:\n",
    "                    proteinswith[dom]= set([p])\n",
    "            issingledom[p] = check_single_domain(p)\n",
    "            included_proteins_with_domain.append(p)\n",
    "        except:\n",
    "            a = 7\n",
    "    single_domains =  [x for x in included_proteins_with_domain if issingledom[x]]\n",
    "    with open(pickled_data_path, 'wb') as f:\n",
    "        pickle.dump([interaction_idx, interact,drugsof,included_proteins_with_domain,proteinswith,domainsof,issingledom], f)\n",
    "\n",
    "else:# when the file doesn't exist or we force to reload the data\n",
    "    with open(pickled_data_path, 'rb') as f:\n",
    "        [interaction_idx, interact,drugsof,included_proteins_with_domain,proteinswith,domainsof,issingledom] = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find all the triples that can serve as examples for problem one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here we do the calculations, meaning we prepare the table consisting of pairs of single domain proteins (P) and interacting drugs (D) the number of proteins falling to each of the three groups and the ID of these proteins are stored in the next columns\n",
    "\n",
    "drug_level_examples = \"onedomain-protein,domain,interacting_drug,num_pos,num_neg,num_unk,pos,neg,unk\\n\"\n",
    "protein_level_exmples  = \"\"\n",
    "\n",
    "\n",
    "pdq_triples =set()\n",
    "drug_domain_pairs = set()\n",
    "domain_set = set()\n",
    "\n",
    "for p in single_domains:\n",
    "    m = domainsof[p][0]\n",
    "    Q_set = proteinswith[m].copy()\n",
    "    if p in Q_set:\n",
    "        Q_set.remove(p)        \n",
    "    if p in drugsof:\n",
    "        D_set = drugsof[p]\n",
    "        for d in D_set:\n",
    "            negs = []\n",
    "            pos = []\n",
    "            unk= []\n",
    "            for q in Q_set:\n",
    "                if type(q)== float:\n",
    "                    print(\"error-q:\", q)\n",
    "                if (q,d) in interact:\n",
    "                    if interact[(q,d)]:\n",
    "                        pos.append(q)\n",
    "                    else:\n",
    "                        drug_domain_pairs.add((m,d))\n",
    "                        pdq_triples.add((p,d,q))\n",
    "                        domain_set.add(m)\n",
    "                        negs.append(q)\n",
    "                else:\n",
    "                    unk.append(q)\n",
    "            if (type(p) == float):\n",
    "                print(\"error-p:\", p)\n",
    "            if (type(m) == float):\n",
    "                print(\"error-m:\", m)\n",
    "            if (type(d) == float):\n",
    "                print(\"error-d:\", d)                \n",
    "            row_str= \",\".join ([p,m,d,str(len(pos)),str(len(negs)),str(len(unk)),\";\".join(pos), \";\".join(negs), \";\".join(unk)])+\"\\n\"\n",
    "            drug_level_examples += row_str\n",
    "            \n",
    "with open(\"outputs/problem1examples_10_30.csv\",\"w\") as outf:\n",
    "    outf.writelines(drug_level_examples)\n",
    "\n",
    "Q_pos = dict()\n",
    "Q_neg = dict()\n",
    "for dom,dd in drug_domain_pairs:\n",
    "    for prot in  proteinswith[dom]:\n",
    "        if (prot, dd) in interact:\n",
    "            if interact[(prot,dd)]:\n",
    "                if (dom,dd) in Q_pos:\n",
    "                    Q_pos[(dom,dd)].add(prot)\n",
    "                else:\n",
    "                    Q_pos[(dom,dd)] = set([prot])\n",
    "            else:\n",
    "                if (dom,dd) in Q_neg:\n",
    "                    Q_neg[(dom,dd)].add(prot)\n",
    "                else:\n",
    "                    Q_neg[(dom,dd)] = set([prot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdq_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drug_domain_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Createing report of found examples\n",
    "\n",
    "since we learned that even with imposing these restirctions, we have close to one thoasand examples left, we generate the report based on these examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###second way of visualization\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xmltodict\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "\n",
    "class StringConverter(dict):\n",
    "    def __contains__(self, item):\n",
    "        return True\n",
    "    def __getitem__(self, item):\n",
    "        return str\n",
    "    def get(self, default=None):\n",
    "        return str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "shared_dom_col= (0,0.608,0.62,0.8)\n",
    "shared_dom_col_pos= (0,0.608,0.2,0.8)\n",
    "shared_dom_col_neg = (0.62,0.1,0.1,0.8)\n",
    "other_dom_col= (0.6,0.6,0.6,0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# col_names = pandas.read_csv(\"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\", sep = \"\\t\", nrows=0).columns\n",
    "\n",
    "    \n",
    "def visualize(pos_set, neg_set,drug,shared_domain,issingdom,fig_name):\n",
    "    pos_set  = list (pos_set)\n",
    "    neg_set = list(neg_set)\n",
    "    height = len(pos_set)+len(neg_set)\n",
    "    fig = plt.figure(figsize=[8, height])\n",
    "    # text_ax = fig.add_subplot(211)\n",
    "    ax = fig.add_subplot(111)\n",
    "    # text_ax.spines[\"right\"].set_visible(False)\n",
    "    # text_ax.spines[\"left\"].set_visible(False)\n",
    "    # text_ax.spines[\"top\"].set_visible(False)\n",
    "    # text_ax.spines[\"bottom\"].set_visible(False)\n",
    "    # text_ax.get_yaxis().set_visible(False)\n",
    "    # text_ax.get_xaxis().set_visible(False)\n",
    "    max_seq_len = 0\n",
    "    top_to_bottom_idx = 0\n",
    "    y_labels = []\n",
    "    y_ticks = []\n",
    "    \n",
    "    for i in range (len(pos_set)):\n",
    "        vert_idx = height-top_to_bottom_idx\n",
    "        p = pos_set[i]\n",
    "        y_labels += [p]\n",
    "        y_ticks += [vert_idx]       \n",
    "        p_path = domain_data_dir+p+\".xml\"\n",
    "        with open(p_path) as pf:\n",
    "            p_dict = xmltodict.parse(pf.read())\n",
    "        p_seq  = p_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "        p_len  = len (p_seq)\n",
    "        max_seq_len = max(max_seq_len, p_len)\n",
    "        ax.hlines(vert_idx, 0, p_len, linewidth=2, color=\"grey\")\n",
    "        if (issingdom[p]):\n",
    "            ax.scatter([0,p_len],[vert_idx,vert_idx],s=100,c = \"k\")\n",
    "        p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "        if type(p_domains) != list:\n",
    "            p_domains =[p_domains]\n",
    "        for dom in p_domains:\n",
    "            acc = dom[\"@accession\"]\n",
    "            # type = dom[\"@type\"]\n",
    "            begin = int(dom[\"location\"][\"@start\"])\n",
    "            end = int(dom[\"location\"][\"@end\"])\n",
    "            #if pfam_A\n",
    "            if acc==shared_domain:\n",
    "                col = shared_dom_col_pos\n",
    "            else:\n",
    "                col = other_dom_col\n",
    "            ax.hlines(vert_idx, begin, end, linewidth=10, color=col)\n",
    "        top_to_bottom_idx +=1\n",
    "        \n",
    "        \n",
    "    for i in range (len(neg_set)):\n",
    "        vert_idx = height-top_to_bottom_idx\n",
    "        q = neg_set[i]\n",
    "        y_labels += [q]\n",
    "        y_ticks += [vert_idx]       \n",
    "        q_path = domain_data_dir + q + \".xml\"\n",
    "        with open(q_path) as qf:\n",
    "            q_dict = xmltodict.parse(qf.read())\n",
    "        q_seq = q_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "        q_len = len(q_seq)\n",
    "        max_seq_len = max(max_seq_len,q_len)\n",
    "        ax.hlines(vert_idx, 0, q_len, linewidth=2, color=\"grey\")\n",
    "        q_domains = q_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "        if (issingdom[q]):\n",
    "            ax.scatter([0,q_len],[vert_idx,vert_idx],s=100,c = \"k\")\n",
    "        p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "        if type(q_domains) != list:\n",
    "            q_domains =[q_domains]\n",
    "        for dom in q_domains:\n",
    "            acc = dom[\"@accession\"]\n",
    "            # type = dom[\"@type\"]\n",
    "            begin = int(dom[\"location\"][\"@start\"])\n",
    "            end = int(dom[\"location\"][\"@end\"])\n",
    "            # if pfam_A\n",
    "            if acc == shared_domain:\n",
    "                col = shared_dom_col_neg\n",
    "            else:\n",
    "                col = other_dom_col\n",
    "            ax.hlines(vert_idx, begin, end, linewidth=10, color=col)\n",
    "        top_to_bottom_idx +=1\n",
    "        \n",
    "    h_rng = float(max_seq_len)\n",
    "    h_margin = h_rng/10\n",
    "    ax.set_xlim(-h_margin, h_rng+h_margin)\n",
    "    ax.set_ylim(0.5, height+0.5)\n",
    "    # ax.get_yaxis().set_visible(False)\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    \n",
    "#     fig.suptitle(\"Domain: \" + shared_domain+\" and Drug: \")\n",
    "    fig.savefig(fig_name)\n",
    "    plt.close(fig)\n",
    "    \n",
    "#for all domain drug pairs\n",
    "    # show all the positive sets in a table\n",
    "    # show all the neg..\n",
    "    # draw the picture with a list of\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# df = pandas.read_csv(\"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\", sep = \"\\t\",error_bad_lines=False,converters=StringConverter())\n",
    "useful_cols_bindingdb = [\"Ki (nM)\",\"Kd (nM)\",\"IC50 (nM)\",\"EC50 (nM)\",\"kon (M-1-s-1)\",\"koff (s-1)\",\"pH\",\"Temp (C)\"]\n",
    "useful_cols_uniprot = [\"Entry\",\t\"Status\",\"Proteomes\",\"Entry name\",\"Organism\",\"Fragment\",\"Length\"]\n",
    "mdfile = \"# Potential examples for problem 1:\\n\"\n",
    "\n",
    "\n",
    "prot_info_df = pandas.read_csv(\"temp/unique_uniprot_info.tab\",sep= \"\\t\")\n",
    "prot_row_idx   = dict()\n",
    "for index, row in prot_info_df.iterrows():\n",
    "    pid = row[\"yourlist:M202103015C475328CEF75220C360D524E9D456CE1638CDK\"]\n",
    "    prot_row_idx[pid] = index\n",
    "    \n",
    "\n",
    "    \n",
    "for (dom,dd) in Q_pos:\n",
    "    mdfile += \"## domain_drug: \"+dom+\"_\"+dd+\"\\n\\n\"\n",
    "    mdfile += \"### Positives\\n\\n\"\n",
    "    row_idxs = [prot_row_idx[p] for p in Q_pos[dom,dd]]\n",
    "    pos_rows = prot_info_df.loc[row_idxs , useful_cols_uniprot]\n",
    "    mdfile += pos_rows.to_markdown(index = False)+\"\\n\\n\"\n",
    "    mdfile += \"### Negatives\\n\\n\"\n",
    "    row_idxs = [prot_row_idx[p] for p in Q_neg[dom,dd]]\n",
    "    neg_rows = prot_info_df.loc[row_idxs , useful_cols_uniprot]\n",
    "    mdfile += neg_rows.to_markdown(index = False)+\"\\n\\n\"\n",
    "    fig_name =\"outputs/promissing_2/\"+dom+\"_\"+dd+\".svg\"\n",
    "    visualize(Q_pos[(dom,dd)], Q_neg[(dom,dd)],dd,dom,issingledom,fig_name)\n",
    "    mdfile += \"![](\"+dom+\"_\"+dd+\".svg)\\n\\n\"\n",
    "\n",
    "\n",
    "with open(\"outputs/promissing_2/doc.md\", \"w\") as outf:\n",
    "    outf.writelines(mdfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TRASH BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy\n",
    "\n",
    "\n",
    "col_names = pandas.read_csv(\"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\", sep = \"\\t\", nrows=0).columns\n",
    "# types_dict = {\"Ki (nM)\": float,\"Kd (nM)\": float,\"IC50 (nM)\": float,\"EC50 (nM)\": float}\n",
    "# types_dict.update({col: str for col in col_names if col not in types_dict})\n",
    "types_dict={col: str for col in col_names}\n",
    "class StringConverter(dict):\n",
    "    def __contains__(self, item):\n",
    "        return True\n",
    "    def __getitem__(self, item):\n",
    "        return str\n",
    "    def get(self, default=None):\n",
    "        return str\n",
    "\n",
    "df = pandas.read_csv(\"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\", sep = \"\\t\",error_bad_lines=False,converters=StringConverter())\n",
    "single_chain_mask = df[\"Number of Protein Chains in Target (>1 implies a multichain complex)\"]==\"1\"\n",
    "hasswissprot_mask = numpy.logical_not(df[\"UniProt (SwissProt) Primary ID of Target Chain\"].isna())\n",
    "haspubchemcid_mask = numpy.logical_not(df[\"PubChem CID\"].isna())\n",
    "singlechain_idcomplete_mask  = single_chain_mask & hasswissprot_mask & haspubchemcid_mask\n",
    "easy_df = df.loc[singlechain_idcomplete_mask,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selction of the measure and threshold for affinity\n",
    "We use the same criterion used in other papers for defining interactions and non-interactions:\n",
    "- noninteraction: Ki<1000nM or IC50<1000nM\n",
    "- interaction: Ki>30000nM or IC50>30000nM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the mapping of drug protein pair to table rows\n",
    "interaction_idx = dict()\n",
    "idx = 0 \n",
    "for index, row in easy_df.iterrows():\n",
    "    idx+=1\n",
    "    print (\"\\r                       \\rReading \"+str(int(idx*100/len(easy_df)))+\"%\",end = \"\")\n",
    "    pid = row[\"UniProt (SwissProt) Primary ID of Target Chain\"]\n",
    "    did = row[\"PubChem CID\"]\n",
    "    if (pid,did) in interaction_idx:\n",
    "        interaction_idx[(pid,did)].append(index)\n",
    "    else:\n",
    "        interaction_idx[(pid,did)] = [index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here instead of adding a column for binary interactions, we create two dictionaries:\n",
    "# interaction_rows: a dataframe consisting of all rows for pa pair fo drug and protein\n",
    "# iteract: for each pair, if it is decidable, it shows the binary interaction\n",
    "import os\n",
    "\n",
    "interaction_threshold = 1000\n",
    "noninteraction_threshold = 30000\n",
    "\n",
    "def binarize_field(x,l_threshold,h_threshold):\n",
    "    try:\n",
    "        if type(x) != str:\n",
    "            return \"nonstring\"\n",
    "        else:\n",
    "            x_c = x.replace(\">\",\"\")\n",
    "            x_c = x.replace(\"<\",\"\")\n",
    "            x_C = x.replace(\" \",\"\")\n",
    "            val  = float(x_c)\n",
    "            if val == 0:\n",
    "                return \"zero\"\n",
    "            if val>h_threshold:\n",
    "                val_bin = False\n",
    "            elif val<l_threshold:\n",
    "                val_bin = True\n",
    "            else:\n",
    "                return \"middle\"\n",
    "            if val_bin and (\">\" in x):\n",
    "                return \"invalid\"\n",
    "            if (not val_bin) and (\"<\" in x):\n",
    "                return \"invalid\"\n",
    "            return val_bin\n",
    "    except:\n",
    "        return \"error\"\n",
    "\n",
    "    \n",
    "    \n",
    "def binarize(rows):\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    try:\n",
    "        Ki_col= rows[\"Ki (nM)\"].values \n",
    "        IC50_col= rows[\"IC50 (nM)\"].values\n",
    "    except:\n",
    "        Ki_col= [rows[\"Ki (nM)\"]]\n",
    "        IC50_col= [[\"IC50 (nM)\"]]\n",
    "    for i in range(len(Ki_col)):\n",
    "        bin_Ki = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        bin_IC50 = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        if type (bin_Ki)== bool:\n",
    "            if bin_Ki:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "        if type (bin_IC50)== bool:\n",
    "            if bin_IC50:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "    num_all = num_pos + num_neg\n",
    "    if num_all == 0:\n",
    "        return \"undecided_none\"\n",
    "    if num_neg == 0:\n",
    "        return True\n",
    "    if num_pos == 0:\n",
    "        return False\n",
    "    pos_fraction = float(num_pos)/num_all\n",
    "    neg_fraction = float(num_neg)/num_all\n",
    "    if pos_fraction>0.5:\n",
    "        return True\n",
    "    if neg_fraction>0.5:\n",
    "        return False\n",
    "    return \"undceided_conflict\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binarize_strict(rows):\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    try:\n",
    "        Ki_col= rows[\"Ki (nM)\"].values \n",
    "        IC50_col= rows[\"IC50 (nM)\"].values\n",
    "    except:\n",
    "        Ki_col= [rows[\"Ki (nM)\"]]\n",
    "        IC50_col= [[\"IC50 (nM)\"]]\n",
    "    for i in range(len(Ki_col)):\n",
    "        bin_Ki = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        bin_IC50 = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        if (type (bin_Ki)== bool) and (type (bin_IC50)== bool):\n",
    "            if bin_Ki and bin_IC50:\n",
    "                num_pos+=1\n",
    "            elif (not bin_Ki) and (not bin_IC50):\n",
    "                num_neg+=1            \n",
    "        elif type (bin_Ki)== bool:\n",
    "            if bin_Ki:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "        elif type (bin_IC50)== bool:\n",
    "            if bin_IC50:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "    num_all = num_pos + num_neg\n",
    "    if num_all == 0:\n",
    "        return \"undecided_none\"\n",
    "    if num_neg == 0:\n",
    "        return True\n",
    "    if num_pos == 0:\n",
    "        return False\n",
    "#     pos_fraction = float(num_pos)/num_all\n",
    "#     neg_fraction = float(num_neg)/num_all\n",
    "#     if pos_fraction>0.5:\n",
    "#         return True\n",
    "#     if neg_fraction>0.5:\n",
    "#         return False\n",
    "    return \"undceided_conflict\"\n",
    "\n",
    "\n",
    "\n",
    "interact = dict()\n",
    "drugsof = dict()\n",
    "idx = 0 \n",
    "for (p,d) in interaction_idx:\n",
    "    idx+=1\n",
    "    print (\"\\r                       \\rBinarizing \"+str(int(idx*100/len(interaction_idx)))+\"%\",end = \"\")\n",
    "    res = binarize_strict(easy_df.loc[interaction_idx[(p,d)],:])\n",
    "    if type(res)== bool:\n",
    "        interact[(p,d)] = res\n",
    "        if res:\n",
    "            if p in drugsof:\n",
    "                drugsof[p].add(d)\n",
    "            else:\n",
    "                drugsof[p] = {d}\n",
    "\n",
    "target_uniprots  = easy_df[\"UniProt (SwissProt) Primary ID of Target Chain\"].values\n",
    "unique_target_uniprots  = set(target_uniprots)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we dump the list of proteins (uniprot IDs) so that we can go and download their pfam domains from the uniprot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_uniprots  = easy_df[\"UniProt (SwissProt) Primary ID of Target Chain\"].values\n",
    "unique_target_uniprots  = set(target_uniprots)\n",
    "with open(\"unique_uniprots.txt\", \"w\") as outf:\n",
    "    outf.writelines(\"\\n\".join(unique_target_uniprots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we already have them we ignore this part and just read them from the downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "from os import path\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "\n",
    "template = 'http://pfam.xfam.org/protein/P09482?output=xml'\n",
    "\n",
    "domain_data_dir = \"temp/domain_details/\"\n",
    "\n",
    "blank_length_threshold = 30\n",
    "\n",
    "\n",
    "def pfam_record_dict(p):\n",
    "    p_path = domain_data_dir + p + \".xml\"\n",
    "    if not path.exists(p_path):\n",
    "        url = \"http://pfam.xfam.org/protein/\"+p+\"?output=xml\"\n",
    "        req = requests.get(url)\n",
    "        with open (domain_data_dir+prot+\".xml\",\"w\") as outf:\n",
    "            outf.writelines(req.text)\n",
    "            \n",
    "    with open(p_path) as pf:\n",
    "        p_dict = xmltodict.parse(pf.read())\n",
    "    return p_dict\n",
    "\n",
    "def pfam_domains(p):\n",
    "    p_dict = pfam_record_dict(p)\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    return p_domains\n",
    "\n",
    "def specie_name(p):\n",
    "    p_dict  = pfam_record_dict(p)\n",
    "    return p_dict[\"pfam\"][\"entry\"][\"taxonomy\"][\"@species_name\"]\n",
    "\n",
    "\n",
    "def is_single_domain(p):\n",
    "    p_dict = pfam_record_dict(p)\n",
    "    p_seq  = p_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "    p_len  = len (p_seq)\n",
    "    on_domain =[False]*p_len\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    if type(p_domains) != list:\n",
    "        p_domains =[p_domains]\n",
    "    for dom in p_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        # type = dom[\"@type\"]\n",
    "        begin = int(dom[\"location\"][\"@start\"])-1\n",
    "        end = int(dom[\"location\"][\"@end\"])-1\n",
    "        on_domain[begin:end]  = [True] * ((end-begin)+1)\n",
    "    streak = 0 \n",
    "    max_streak = 0\n",
    "    for i in range(p_len):\n",
    "        if on_domain[i]:\n",
    "            streak = 0            \n",
    "        else:\n",
    "            streak += 1\n",
    "            max_streak  = max(streak, max_streak)\n",
    "            \n",
    "    if (max_streak > blank_length_threshold) or (len(p_domains)>1):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we read the domain annotations we have downloaded from uniprot.\n",
    "\n",
    "import pandas\n",
    "\n",
    "def extract_items(field):\n",
    "    if \";\" not in field:\n",
    "        return []\n",
    "    else:\n",
    "        spl = field.split(\";\")\n",
    "        for s in spl:\n",
    "            if len(s) <=1:\n",
    "#                 print(s)\n",
    "                spl.remove(s)\n",
    "        return spl\n",
    "\n",
    "    \n",
    "    \n",
    "proteinswith = dict() #for each domain (pfam ID), this will store the set of proteins (uniprot IDs) that have this domain\n",
    "domainsof  = dict () #for each protein (uniprot ID), this will store the list of domains (pfam IDs) of that protein\n",
    "df = pandas.read_csv(\"temp/unique_uniprots_domains.tab\", sep = \"\\t\", converters={i: str for i in range(100)})\n",
    "\n",
    "for index , row in df.iterrows():\n",
    "    domain_field = row [\"Cross-reference (Pfam)\"]\n",
    "    pid = row[\"yourlist:M20210208A94466D2655679D1FD8953E075198DA843865FQ\"]    \n",
    "    if True: #conditions for considering a protien such as being human protein or being reviewed\n",
    "            domain_list = extract_items(domain_field)\n",
    "            domainsof[pid]= domain_list \n",
    "            for dom  in domain_list:\n",
    "                if dom in proteinswith:\n",
    "                    proteinswith[dom].append(pid)\n",
    "                else:\n",
    "                    proteinswith[dom]= [pid]\n",
    "        \n",
    "    \n",
    "num_domains = {x:len(domainsof[x]) for x in domainsof.keys()}\n",
    "one_domain = [x for x in domainsof.keys() if len(domainsof[x])==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### both proteins being a human protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_domain_human_pdq_triples = []\n",
    "for (pp,dd,qq) in single_domain_pdq_triples:\n",
    "    if (specie_name(pp)==\"Homo sapiens (Human)\") and (specie_name(qq) == \"Homo sapiens (Human)\"):\n",
    "        single_domain_human_pdq_triples.append((pp,dd,qq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xmltodict\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "\n",
    "class StringConverter(dict):\n",
    "    def __contains__(self, item):\n",
    "        return True\n",
    "    def __getitem__(self, item):\n",
    "        return str\n",
    "    def get(self, default=None):\n",
    "        return str\n",
    "\n",
    "\n",
    "\n",
    "domain_data_dir = \"temp/domain_details/\"\n",
    "shared_dom_col= (0,0.608,0.62,0.8)\n",
    "other_dom_col= (0.6,0.6,0.6,0.8)\n",
    "\n",
    "\n",
    "def visualize(p,q,shared_domain):\n",
    "    fig = plt.figure(figsize=[8, 2])\n",
    "    # text_ax = fig.add_subplot(211)\n",
    "    ax = fig.add_subplot(111)\n",
    "    # text_ax.spines[\"right\"].set_visible(False)\n",
    "    # text_ax.spines[\"left\"].set_visible(False)\n",
    "    # text_ax.spines[\"top\"].set_visible(False)\n",
    "    # text_ax.spines[\"bottom\"].set_visible(False)\n",
    "    # text_ax.get_yaxis().set_visible(False)\n",
    "    # text_ax.get_xaxis().set_visible(False)\n",
    "\n",
    "    p_path = domain_data_dir+p+\".xml\"\n",
    "    with open(p_path) as pf:\n",
    "        p_dict = xmltodict.parse(pf.read())\n",
    "    p_seq  = p_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "    p_len  = len (p_seq)\n",
    "    ax.hlines(2, 0, p_len, linewidth=2, color=\"grey\")\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    \n",
    "    if type(p_domains) != list:\n",
    "        p_domains =[p_domains]\n",
    "    for dom in p_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        # type = dom[\"@type\"]\n",
    "        begin = int(dom[\"location\"][\"@start\"])\n",
    "        end = int(dom[\"location\"][\"@end\"])\n",
    "        #if pfam_A\n",
    "        if acc==shared_domain:\n",
    "            col = shared_dom_col\n",
    "        else:\n",
    "            col = other_dom_col\n",
    "        ax.hlines(2, begin, end, linewidth=10, color=col)\n",
    "\n",
    "    q_path = domain_data_dir + q + \".xml\"\n",
    "    with open(q_path) as qf:\n",
    "        q_dict = xmltodict.parse(qf.read())\n",
    "    q_seq = q_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "    q_len = len(q_seq)\n",
    "    ax.hlines(1, 0, q_len, linewidth=2, color=\"grey\")\n",
    "    q_domains = q_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    if type(q_domains) != list:\n",
    "        q_domains =[q_domains]\n",
    "    for dom in q_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        # type = dom[\"@type\"]\n",
    "        begin = int(dom[\"location\"][\"@start\"])\n",
    "        end = int(dom[\"location\"][\"@end\"])\n",
    "        # if pfam_A\n",
    "        if acc == shared_domain:\n",
    "            col = shared_dom_col\n",
    "        else:\n",
    "            col = other_dom_col\n",
    "        ax.hlines(1, begin, end, linewidth=10, color=col)\n",
    "\n",
    "    h_rng = float(max(p_len,q_len))\n",
    "    h_margin = h_rng/10\n",
    "    ax.set_xlim(-h_margin, h_rng+h_margin)\n",
    "    ax.set_ylim(0.5, 2.5)\n",
    "    # ax.get_yaxis().set_visible(False)\n",
    "    p_label = \"P [\"+p+\"]\"\n",
    "    q_label  = \"Q [\"+q+\"]\"\n",
    "    ax.set_yticks([1,2])\n",
    "    ax.set_yticklabels([q_label,p_label])\n",
    "    fig_fname =\"outputs/promissing_2/\"+p+\"_\"+d+\"_\"+q+\".svg\"\n",
    "    fig.suptitle(\"Domain: \" + shared_domain)\n",
    "    fig.savefig(fig_fname)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# col_names = pandas.read_csv(\"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\", sep = \"\\t\", nrows=0).columns\n",
    "\n",
    "\n",
    "# df = pandas.read_csv(\"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\", sep = \"\\t\",error_bad_lines=False,converters=StringConverter())\n",
    "useful_cols = [\"Ki (nM)\",\"Kd (nM)\",\"IC50 (nM)\",\"EC50 (nM)\",\"kon (M-1-s-1)\",\"koff (s-1)\",\"pH\",\"Temp (C)\"]\n",
    "mdfile = \"# Potential examples for problem 1:\\n\"\n",
    "\n",
    "prot_info_df = pandas.read_csv(\"unique_uniprot_info.tab\")\n",
    "prot_row_idx   = dict()\n",
    "for index, row in prot_info_df.iterrows():\n",
    "    pid = row[\"yourlist:M202103015C475328CEF75220C360D524E9D456CE1638CDK\"]\n",
    "    prot_row_idx[pid] = index\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for (p,d,q) in single_domain_pdq_triples:\n",
    "    m = domainsof[p][0]\n",
    "    visualize(p,q,m)\n",
    "    mdfile += \"## Interaction between domain \"+m+\" and drug \"+d+\"\\n\\n\"\n",
    "#     p_rows_mask = (easy_df[\"UniProt (SwissProt) Primary ID of Target Chain\"] == p) & (easy_df[\"PubChem CID\"] == d)\n",
    "#     q_rows_mask = (easy_df[\"UniProt (SwissProt) Primary ID of Target Chain\"] == q) & (easy_df[\"PubChem CID\"] == d)\n",
    "\n",
    "#     p_rows = easy_df.loc[p_rows_mask, useful_cols].copy()\n",
    "#     q_rows = easy_df.loc[q_rows_mask, useful_cols].copy()\n",
    "    p_rows = easy_df.loc[interaction_idx[(p,d)], useful_cols].copy()\n",
    "    q_rows = easy_df.loc[interaction_idx[(q,d)], useful_cols].copy()\n",
    "\n",
    "    mdfile += \"Single-domain protein (P) interacting with the drug: \" + p +\"\\n\\n\"\n",
    "    mdfile += p_rows.to_markdown(index = False)+\"\\n\\n\"\n",
    "\n",
    "\n",
    "    mdfile += \"Another (Q) protein with the same domain: \" + q +\"\\n\\n\"\n",
    "    mdfile += q_rows.to_markdown(index = False)+\"\\n\\n\"\n",
    "\n",
    "    mdfile += \"![](\"+p+\"_\"+d+\"_\"+q+\".svg)\\n\\n\"\n",
    "\n",
    "with open(\"outputs/promissing_2/doc.md\", \"w\") as outf:\n",
    "    outf.writelines(mdfile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_domain_pdq_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdq_triples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdq_triples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_domain_pdq_triples = []\n",
    "species = []\n",
    "for (pp,dd,qq) in pdq_triples:\n",
    "    dic = valid_single_domain(pp)\n",
    "    species.append(dic[\"pfam\"][\"entry\"][\"taxonomy\"][\"@species_name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1:3] = [True]* ((3-1)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deletions = set()\n",
    "for k in interacts:\n",
    "    if (type(k[0])!=str or type(k[1]) !=str):\n",
    "        deletions.add(k)\n",
    "for i in deletions:\n",
    "    del interacts[i]\n",
    "len(interacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a piece of code for checking and example\n",
    "# it takes a protein p and a protein q and a drug d and prints all rows with p and d and then all rows with q and d \n",
    "# the columns that we want are the \n",
    "p = \"P58154\"\n",
    "q = \"P09482\"\n",
    "d = \"86418\"\n",
    "useful_cols = [\"UniProt (SwissProt) Primary ID of Target Chain\",\"PubChem CID\",\"Ki (nM)\",\"Kd (nM)\",\"IC50 (nM)\",\"EC50 (nM)\",\"kon (M-1-s-1)\",\"koff (s-1)\",\"pH\",\"Temp (C)\"]\n",
    "\n",
    "##first print information about p \n",
    "p_rows = (df[\"UniProt (SwissProt) Primary ID of Target Chain\"]== p) & (df[\"PubChem CID\"]== d)\n",
    "first_row_number = numpy.nonzero(numpy.array(p_rows))[0]\n",
    "p_seq = df.loc[first_row_number,\"BindingDB Target Chain  Sequence\"].values[0]\n",
    "\n",
    "\n",
    "q_rows = (df[\"UniProt (SwissProt) Primary ID of Target Chain\"]== q) & (df[\"PubChem CID\"]== d)\n",
    "first_row_number = numpy.nonzero(numpy.array(q_rows))[0]\n",
    "q_seq = df.loc[first_row_number,\"BindingDB Target Chain  Sequence\"].values[0]\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "template = 'http://pfam.xfam.org/protein/P09482?output=xml'\n",
    "\n",
    "for prot in unique_target_uniprots:\n",
    "    print(\"                                       \\r\"+\"Downloading \"+prot, end  =\"\")\n",
    "    url = \"http://pfam.xfam.org/protein/\"+prot+\"?output=xml\"\n",
    "    req = requests.get(url)\n",
    "    with open (\"temp/domain_details/\"+prot+\".xml\",\"w\") as outf:\n",
    "        outf.writelines(req.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.fromstring(req.text)\n",
    "# root.getchildren()\n",
    "# for child in root.iter(\"https://pfam.xfam.org/}pfam\"):\n",
    "#     print(child.tag,  child.text)\n",
    "dd = etree_to_dict(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in root.findall(\".//{https://pfam.xfam.org/}match\"):\n",
    "    print(node.tag, node.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def extract_items(field):\n",
    "    if \";\" not in field:\n",
    "        return []\n",
    "    else:\n",
    "        spl = field.split(\";\")\n",
    "        for s in spl:\n",
    "            if len(s) <=1:\n",
    "#                 print(s)\n",
    "                spl.remove(s)\n",
    "        return spl\n",
    "                \n",
    "    \n",
    "            \n",
    "    \n",
    "\n",
    "df = pandas.read_csv(\"uniprot.tab\", sep =\"\\t\",dtype=str)\n",
    "\n",
    "n_rows, n_cols  = df.shape\n",
    "\n",
    "uniprot_ids = df[\"Entry\"]\n",
    "pfam_ids = df[\"Cross-reference (Pfam)\"].astype(str).values\n",
    "chembl_ids = df[\"Cross-reference (ChEMBL)\"].astype(str).values\n",
    "\n",
    "domain_count = dict()\n",
    "drug_count = dict()\n",
    "\n",
    "\n",
    "for i in range (n_rows):\n",
    "    domain_list = extract_items(pfam_ids[i])\n",
    "    drug_list = extract_items(chembl_ids[i])\n",
    "    for dom in domain_list:\n",
    "        if dom in domain_count:\n",
    "            domain_count[dom] += 1\n",
    "        else:\n",
    "            domain_count[dom] = 1\n",
    "    \n",
    "    for drug in drug_list:\n",
    "        if drug in drug_count:\n",
    "            drug_count[drug] += 1\n",
    "        else:\n",
    "            drug_count[drug] = 1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping human proteins to pfam domains and DrugBank drugs\n",
    "this allows us to study the prevalence of mullti-domain prorteins. Each multi-domain protein is a case where the problem two can happen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above scripts allows us to count for each domain the number of proteins that have that domain\n",
    "we will follow the rest of the job later but for now we focus on the approach where affinity data are used for considering true negative interactinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "952161## Studying the first problem\n",
    "for this, we want to collect all human proteins and thier interactions, and look at all single-domain proteins and see the support and confidence for  association between domains and interactions. For a certain domain $\\text{M}$, the support will be the the fraction of human proteins that have domain $M$ and the confidene for a drug $D$ will be:\n",
    "\n",
    "$$ \\frac{\\text{Number of proteins that have $M$ and interact with $D$}}{\\text{Number of proteins with $M$}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using negative interactions to find examples of problem one\n",
    "\n",
    "Here we use a dataset from the [paper](https://doi.org/10.1371/journal.pcbi.1005219). In this paper they have used BindingDB and BioLIP to build a dataset of both positive and negative interactions between proteins and drugs. An affinity threshold have been used to consider them negative.\n",
    "\n",
    "After having negative interactions we need to find the cases where a drug interacts with a protein with only domain M but it doesn't interact with the many other proteins that have domain M \n",
    "\n",
    "to find these examples we devise an algorithm:\n",
    "\n",
    "   \n",
    "    for each domain M:\n",
    "        find all proteins that only have M as their domain and put them in set P\n",
    "        D = {}\n",
    "        for each protein p in P:\n",
    "            add to D all drugs that ineract with P\n",
    "        //on paper, since domain M interacts with all drugs in D, then all proteins with M should also interact with all drugs in D\n",
    "        for each drug d in D:\n",
    "        if any of the proteins Q in NEG(d) has domain D then save them save (p, M, q) in the set of couter examples\n",
    "\n",
    "\n",
    "so for this we need to have set of all domains and sort them based on frequency. \n",
    "for each domain we need all of the proteins that have it and for each protein \n",
    "            \n",
    "            \n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
