{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through these experiments, we want to show two issues in studying interaction between drugs and domains.\n",
    "1. **First problem:** That when a drug interacts with a single-domain protein (with domain X), even if we correctly conclude that it interacts with domain X, It may not interact with another single domain protein that has domain X. This is easy to check using Data. For this, we need some negative interaction data and for that, we can go to affinity data.  \n",
    "2. **Second Problem:** is about multi-domain proteins and that is when a drug is interacting with a multi-domain protein (with domains X and Y), we canâ€™t confidently say if this drug interacts with X or Y or both or either or neither meaning several cases are possible:  \n",
    "    - The drug interacts with protein because it interacts directly with X\n",
    "    - The drug interacts with protein because it interacts directly with Y\n",
    "    - The drug interacts with protein because X and Y are both present\n",
    "    - The drug interacts with protein because either of X or Y are present\n",
    "    - The drug interacts because X and Y are present and they are in certain configuration with respect to each other or other extrinsic properties of the protein besides existence of X and Y.\n",
    "    - The drug interacts for a completely irrelevant reason to existence of X or Y. \n",
    "    \n",
    "There might be some overlap between the problem-1 and problem-2. But conceptually, we can say that first problem arises when trying to go from a drug-domain interaction to drug-protein interaction and the second problem arises when we go in the reverse direction. We want to see if we can quantitatively assess how prevalent these problems are or at least illuminate them as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from positive interactions to negative\n",
    "This means we infer drug-domain interactions from drug interactions of single domain proteins, and then find examples where the same domain occurs in other proteins but doesn't interact with same drugs (we have a negative interaction for it in our dataset). for this, the negative interactions are very important. common drug-target interaction databases only have positive interactions and they assume lack of a pair in the dataset to mean lack of interaction, which is obviously not correct. However there are some researches that also collect negative interaction data like [Coelho2016](https://doi.org/10.1371/journal.pcbi.1005219) where they have used affinity data to extract some negative interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt using Coelho2016 datset\n",
    "This dataset is based on [Coelho2016](https://doi.org/10.1371/journal.pcbi.1005219) paper and contains negative and positive interactions. Negative interactions are extracted from BindingDB and BioLip databases, even though BioLip is questionable as a source of negative interactions because it is extracted from strucutres of drug-target complexes in the PDB, while we are more interested in those based on chemical assays.\n",
    "To use this dataset to search for cases of problem-1, we create a table where for each pair of drug D and proteins P, where the protein is single-domain M, we list all other proteins Q that have the same domain M and divide them into three groups:\n",
    "1. **Pos:** those that there is a positive interaction in the dataset between Q and D\n",
    "1. **Neg:** those that there is a negative interaction in the dataset between Q and D\n",
    "1. **Unk:** those that there is no interaction information in the dataset between Q and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#first we read the dataset and \n",
    "\n",
    "interacts = dict() # for each pair in the dataset (key),  it shows the annotations True/False (interaction/non-interaction) if it exists in the dataset. we basically store all dataset infromation here.\n",
    "uniprot_ids = set() # set of uniprot IDs for the purpose of collecting their pfam domain annotations\n",
    "drugsof= dict() # we want positive interactions for single domain proteins so we store them here to be readily available\n",
    "\n",
    "import pandas\n",
    "for f in [\"drugbank_DTIs_REAL_NEGS.txt\",\"test_data_sc_and_bc.txt\",\"yamanishi_DTIs_REAL_NEGS.txt\"]:\n",
    "    df = pandas.read_csv(\"DTIPred/\"+f, sep = \"\\t\", header = None)\n",
    "    for index , row in df.iterrows():\n",
    "        pid  = row[0]\n",
    "        did  = row[1]\n",
    "        interaction_exist  = row[2]\n",
    "        uniprot_ids.add(pid)\n",
    "#         if (pid,did) in interacts:\n",
    "#             if (interacts[(pid,did)] != interaction_exist):\n",
    "#                 print (\"error repeat\", (pid,did))\n",
    "#         else:\n",
    "        interacts[(pid,did)] = interaction_exist \n",
    "        if interaction_exist == 1:               \n",
    "            if pid in drugsof:\n",
    "                drugsof[pid].append(did)\n",
    "            else:\n",
    "                drugsof[pid] = [did]\n",
    "        \n",
    "with open (\"DTIPred/uniprotids.txt\", \"w\") as pf:\n",
    "    pf.writelines(\"\\n\".join(uniprot_ids))\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here, we read the domain annotations we have downloaded from uniprot.\n",
    "\n",
    "import pandas\n",
    "\n",
    "def extract_items(field):\n",
    "    if \";\" not in field:\n",
    "        return []\n",
    "    else:\n",
    "        spl = field.split(\";\")\n",
    "        for s in spl:\n",
    "            if len(s) <=1:\n",
    "#                 print(s)\n",
    "                spl.remove(s)\n",
    "        return spl\n",
    "\n",
    "proteinswith = dict() #for each domain (pfam ID), this will store the set of proteins (uniprot IDs) that have this domain\n",
    "domainsof  = dict () #for each protein (uniprot ID), this will store the list of domains (pfam IDs) of that protein\n",
    "df = pandas.read_csv(\"DTIPred/uniprotids_annnots.tab\", sep = \"\\t\", converters={i: str for i in range(100)})\n",
    "\n",
    "for index , row in df.iterrows():\n",
    "    domain_field = row [\"Cross-reference (Pfam)\"]\n",
    "    pid = row[\"yourlist:M20210201A94466D2655679D1FD8953E075198DA83D46A3C\"]    \n",
    "    if True: #conditions for considering a protien such as being human protein or being reviewed\n",
    "            domain_list = extract_items(domain_field)\n",
    "            domainsof[pid]= domain_list \n",
    "            for dom  in domain_list:\n",
    "                if dom in proteinswith:\n",
    "                    proteinswith[dom].append(pid)\n",
    "                else:\n",
    "                    proteinswith[dom]= [pid]\n",
    "        \n",
    "    \n",
    "num_domains = {x:len(domainsof[x]) for x in domainsof.keys()}\n",
    "one_domain = [x for x in domainsof.keys() if len(domainsof[x])==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here we do the calculations, meaning we prepare the table consisting of pairs of single domain proteins (P) and interacting drugs (D) the number of proteins falling to each of the three groups and the ID of these proteins are stored in the next columns\n",
    "\n",
    "drug_level_examples = \"onedomain-protein,domain,interacting_drug,num_pos,num_neg,num_unk,pos,neg,unk\\n\"\n",
    "protein_level_exmples  = \"\"\n",
    "\n",
    "\n",
    "for p in one_domain:\n",
    "    m = domainsof[p][0]\n",
    "    Q_set = proteinswith[m].copy()\n",
    "    if p in Q_set:\n",
    "        Q_set.remove(p)        \n",
    "    if p in drugsof:\n",
    "        D_set = drugsof[p]\n",
    "        for d in D_set:\n",
    "            negs = []\n",
    "            pos = []\n",
    "            unk= []\n",
    "            for q in Q_set:\n",
    "                if (q,d) in interacts:\n",
    "                    if interacts[(q,d)]==1:\n",
    "                        pos.append(q)\n",
    "                    else:\n",
    "                        negs.append(q)\n",
    "                else:\n",
    "                    unk.append(q)\n",
    "            row_str= \",\".join ([p,m,d,str(len(pos)),str(len(negs)),str(len(unk)),\";\".join(pos), \";\".join(negs), \";\".join(unk)])+\"\\n\"\n",
    "            drug_level_examples+= row_str\n",
    "            \n",
    "with open(\"result_drug_level.csv\",\"w\") as outf:\n",
    "    outf.writelines(drug_level_examples)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this experiments showed that we couldn't find occurance of the problem-1 with this dataset. This can be due to small number of negative interactions that we have which can be due the the dataset being old. Therefore, we recollect the negative interactions from BindingDB to do this experiment again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second attempt using BindingDB\n",
    "we downloaded the BindingDB in tsv format. There were few issues here. First of all, for affinity, there are several measures here including Ki, Kd, IC50, and EC50. The literature that use affinity to obtain negative interactions don't clarfiy which of these measures they have used except one preprint that says they use Ki or IC50, even though based on a search that I did Kd is the most relevant measure for durg binding to proteins. \n",
    "Another problem is that some of the rows (interactions) in the bindingDB don't have a uniprot ID or have multiple chains. these cases altogether constitute less than 13% of interactions in the dataset. So for now, we ignore them because it makes the life much easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the dataset and store binary interactions or read these information from the pickled file\n",
    "\n",
    "\n",
    "reload_dataset= False\n",
    "interaction_threshold = 1000\n",
    "noninteraction_threshold = 30000\n",
    "blank_length_threshold = 30\n",
    "bindingdb_path = \"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\"\n",
    "domain_data_dir = \"temp/domain_data/\"\n",
    "pickled_data_path = \"temp/pickled_data/data.pickle\"\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas \n",
    "import numpy\n",
    "import pickle\n",
    "import xmltodict\n",
    "from os import path\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "def binarize_field(x,l_threshold,h_threshold):\n",
    "    try:\n",
    "        if type(x) != str:\n",
    "            return \"nonstring\"\n",
    "        else:\n",
    "            x_c = x.replace(\">\",\"\")\n",
    "            x_c = x.replace(\"<\",\"\")\n",
    "            x_C = x.replace(\" \",\"\")\n",
    "            val  = float(x_c)\n",
    "            if val == 0:\n",
    "                return \"zero\"\n",
    "            if val>h_threshold:\n",
    "                val_bin = False\n",
    "            elif val<l_threshold:\n",
    "                val_bin = True\n",
    "            else:\n",
    "                return \"middle\"\n",
    "            if val_bin and (\">\" in x):\n",
    "                return \"invalid\"\n",
    "            if (not val_bin) and (\"<\" in x):\n",
    "                return \"invalid\"\n",
    "            return val_bin\n",
    "    except:\n",
    "        return \"error\"\n",
    "\n",
    "    \n",
    "    \n",
    "def binarize(rows):\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    try:\n",
    "        Ki_col= rows[\"Ki (nM)\"].values \n",
    "        IC50_col= rows[\"IC50 (nM)\"].values\n",
    "    except:\n",
    "        Ki_col= [rows[\"Ki (nM)\"]]\n",
    "        IC50_col= [[\"IC50 (nM)\"]]\n",
    "    for i in range(len(Ki_col)):\n",
    "        bin_Ki = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        bin_IC50 = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        if type (bin_Ki)== bool:\n",
    "            if bin_Ki:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "        if type (bin_IC50)== bool:\n",
    "            if bin_IC50:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "    num_all = num_pos + num_neg\n",
    "    if num_all == 0:\n",
    "        return \"undecided_none\"\n",
    "    if num_neg == 0:\n",
    "        return True\n",
    "    if num_pos == 0:\n",
    "        return False\n",
    "    pos_fraction = float(num_pos)/num_all\n",
    "    neg_fraction = float(num_neg)/num_all\n",
    "    if pos_fraction>0.5:\n",
    "        return True\n",
    "    if neg_fraction>0.5:\n",
    "        return False\n",
    "    return \"undceided_conflict\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binarize_strict(rows):\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    try:\n",
    "        Ki_col= rows[\"Ki (nM)\"].values \n",
    "        IC50_col= rows[\"IC50 (nM)\"].values\n",
    "    except:\n",
    "        Ki_col= [rows[\"Ki (nM)\"]]\n",
    "        IC50_col= [[\"IC50 (nM)\"]]\n",
    "    for i in range(len(Ki_col)):\n",
    "        bin_Ki = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        bin_IC50 = binarize_field(Ki_col[i],interaction_threshold, noninteraction_threshold)\n",
    "        if (type (bin_Ki)== bool) and (type (bin_IC50)== bool):\n",
    "            if bin_Ki and bin_IC50:\n",
    "                num_pos+=1\n",
    "            elif (not bin_Ki) and (not bin_IC50):\n",
    "                num_neg+=1            \n",
    "        elif type (bin_Ki)== bool:\n",
    "            if bin_Ki:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "        elif type (bin_IC50)== bool:\n",
    "            if bin_IC50:\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "    num_all = num_pos + num_neg\n",
    "    if num_all == 0:\n",
    "        return \"undecided_none\"\n",
    "    if num_neg == 0:\n",
    "        return True\n",
    "    if num_pos == 0:\n",
    "        return False\n",
    "#     pos_fraction = float(num_pos)/num_all\n",
    "#     neg_fraction = float(num_neg)/num_all\n",
    "#     if pos_fraction>0.5:\n",
    "#         return True\n",
    "#     if neg_fraction>0.5:\n",
    "#         return False\n",
    "    return \"undceided_conflict\"\n",
    "\n",
    "class StringConverter(dict):\n",
    "    def __contains__(self, item):\n",
    "        return True\n",
    "    def __getitem__(self, item):\n",
    "        return str\n",
    "    def get(self, default=None):\n",
    "        return str\n",
    "\n",
    "def extract_items(field):\n",
    "    if \";\" not in field:\n",
    "        return []\n",
    "    else:\n",
    "        spl = field.split(\";\")\n",
    "        for s in spl:\n",
    "            if len(s) <=1:\n",
    "    #                 print(s)\n",
    "                spl.remove(s)\n",
    "        return spl\n",
    "\n",
    "\n",
    "def pfam_record_dict(p):\n",
    "    p_path = domain_data_dir + p + \".xml\"\n",
    "    if not path.exists(p_path):\n",
    "        url = \"http://pfam.xfam.org/protein/\"+p+\"?output=xml\"\n",
    "        req = requests.get(url)\n",
    "        with open (domain_data_dir+prot+\".xml\",\"w\") as outf:\n",
    "            outf.writelines(req.text)\n",
    "            \n",
    "    with open(p_path) as pf:\n",
    "        p_dict = xmltodict.parse(pf.read())\n",
    "    return p_dict\n",
    "\n",
    "def get_domains(p):\n",
    "    p_dict = pfam_record_dict(p)\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    domain_list =[]\n",
    "    if type(p_domains) != list:\n",
    "        p_domains =[p_domains]\n",
    "    for dom in p_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        domain_list.append(acc)\n",
    "    return domain_list\n",
    "\n",
    "# def specie_name(p):\n",
    "#     p_dict  = pfam_record_dict(p)\n",
    "#     return p_dict[\"pfam\"][\"entry\"][\"taxonomy\"][\"@species_name\"]\n",
    "\n",
    "\n",
    "def check_single_domain(p):\n",
    "    p_dict = pfam_record_dict(p)\n",
    "    p_seq  = p_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "    p_len  = len (p_seq)\n",
    "    on_domain =[False]*p_len\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    if type(p_domains) != list:\n",
    "        p_domains =[p_domains]\n",
    "    for dom in p_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        # type = dom[\"@type\"]\n",
    "        begin = int(dom[\"location\"][\"@start\"])-1\n",
    "        end = int(dom[\"location\"][\"@end\"])-1\n",
    "        on_domain[begin:end]  = [True] * ((end-begin)+1)\n",
    "    streak = 0 \n",
    "    max_streak = 0\n",
    "    for i in range(p_len):\n",
    "        if on_domain[i]:\n",
    "            streak = 0            \n",
    "        else:\n",
    "            streak += 1\n",
    "            max_streak  = max(streak, max_streak)\n",
    "            \n",
    "    if (max_streak > blank_length_threshold) or (len(p_domains)>1):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "import sys\n",
    "import io\n",
    "binfileexist = os.path.exists(pickled_data_path)\n",
    "\n",
    "if (not binfileexist) or reload_dataset:\n",
    "#     col_names = pandas.read_csv(\"data/BindingDB_All_2021m0.tsv/BindingDB_All.tsv\", sep = \"\\t\", nrows=0).columns\n",
    "    print (\"Reading Binding DB file...\",end = \"\")\n",
    "\n",
    "    save_stderr = sys.stderr\n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "    df = pandas.read_csv(bindingdb_path, sep = \"\\t\",error_bad_lines=False,converters=StringConverter())\n",
    "    sys.stderr = save_stderr\n",
    "    \n",
    "    single_chain_mask = df[\"Number of Protein Chains in Target (>1 implies a multichain complex)\"]==\"1\"\n",
    "    hasswissprot_mask = numpy.logical_not(df[\"UniProt (SwissProt) Primary ID of Target Chain\"].isna())\n",
    "    haspubchemcid_mask = numpy.logical_not(df[\"PubChem CID\"].isna())\n",
    "    singlechain_idcomplete_mask  = single_chain_mask & hasswissprot_mask & haspubchemcid_mask\n",
    "    easy_df = df.loc[singlechain_idcomplete_mask,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    interaction_idx = dict()\n",
    "    idx = 0 \n",
    "    for index, row in easy_df.iterrows():\n",
    "        idx+=1\n",
    "        print (\"\\r                                                     \\rGrouping rows by drug-protein pairs \"+str(int(idx*100/len(easy_df)))+\"%\",end = \"\")\n",
    "        pid = row[\"UniProt (SwissProt) Primary ID of Target Chain\"]\n",
    "        did = row[\"PubChem CID\"]\n",
    "        if (pid != \"\") and (did != \"\"):\n",
    "            if (pid,did) in interaction_idx:\n",
    "                interaction_idx[(pid,did)].append(index)\n",
    "            else:\n",
    "                interaction_idx[(pid,did)] = [index]\n",
    "            \n",
    "    interact = dict()\n",
    "    drugsof = dict()\n",
    "    idx = 0\n",
    "    included_proteins = set()\n",
    "    for (p,d) in interaction_idx:\n",
    "        idx+=1\n",
    "        print (\"\\r                                                                          \\rBinarizing \"+str(int(idx*100/len(interaction_idx)))+\"%\",end = \"\")\n",
    "        res = binarize_strict(easy_df.loc[interaction_idx[(p,d)],:])\n",
    "        if type(res)== bool:\n",
    "            interact[(p,d)] = res\n",
    "            included_proteins.add(p)\n",
    "            if res:\n",
    "                if p in drugsof:\n",
    "                    drugsof[p].add(d)\n",
    "                else:\n",
    "                    drugsof[p] = {d}\n",
    "\n",
    "    \n",
    "    issingledom = dict()\n",
    "    proteinswith = dict() #for each domain (pfam ID), this will store the set of proteins (uniprot IDs) that have this domain\n",
    "    domainsof  = dict () \n",
    "    included_proteins_with_domain = []\n",
    "    for p in included_proteins:\n",
    "        try:\n",
    "            domain_list=get_domains(p)\n",
    "            domainsof[p]= domain_list\n",
    "            for dom  in domain_list:\n",
    "                if dom in proteinswith:\n",
    "                    proteinswith[dom].add(p)\n",
    "                else:\n",
    "                    proteinswith[dom]= set([p])\n",
    "            issingledom[p] = check_single_domain(p)\n",
    "            included_proteins_with_domain.append(p)\n",
    "        except:\n",
    "            a = 7\n",
    "    single_domains =  [x for x in included_proteins_with_domain if issingledom[x]]\n",
    "    with open(pickled_data_path, 'wb') as f:\n",
    "        pickle.dump([interaction_idx, interact,drugsof,included_proteins_with_domain,proteinswith,domainsof,issingledom,single_domains], f)\n",
    "\n",
    "else:# when the file exists\n",
    "    with open(pickled_data_path, 'rb') as f:\n",
    "        [interaction_idx, interact,drugsof,included_proteins_with_domain,proteinswith,domainsof,issingledom,single_domains] = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find all the triples that can serve as examples for problem one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we find the examples of problem 1. \n",
    "\n",
    "csv_report_str = \"onedomain-protein,domain,interacting_drug,num_pos,num_neg,num_unk,pos,neg,unk\\n\"\n",
    "# protein_level_exmples  = \"\"\n",
    "\n",
    "\n",
    "problem1_pdq_triples =set()\n",
    "problem1_drug_domain_pairs = set()\n",
    "dataset1_drug_positive_set = set()\n",
    "dataset1_drug_negative_set = set()\n",
    "dataset1_protein_positive_set= set()\n",
    "dataset1_protein_negative_set =set()\n",
    "dataset1_drug_prtein_pairs = set()\n",
    "problem1_domain_set = set()\n",
    "problem1_drug_set = set()\n",
    "domain_set = set()\n",
    "\n",
    "for p in single_domains:\n",
    "    m = domainsof[p][0]\n",
    "    Q_set = proteinswith[m].copy()\n",
    "    if p in Q_set:\n",
    "        Q_set.remove(p)        \n",
    "    if p in drugsof:\n",
    "        D_set = drugsof[p]\n",
    "        for d in D_set:\n",
    "            negs = []\n",
    "            pos = []\n",
    "            unk= []\n",
    "            for q in Q_set:\n",
    "                if type(q)== float:\n",
    "                    print(\"error-q:\", q)\n",
    "                if (q,d) in interact:\n",
    "                    dataset1_drug_prtein_pairs.add((p,d))\n",
    "                    dataset1_drug_prtein_pairs.add((q,d))\n",
    "                    dataset1_protein_positive_set.add(p)\n",
    "                    if interact[(q,d)]:\n",
    "                        pos.append(q)\n",
    "                        dataset1_protein_positive_set.add(q)\n",
    "                        dataset1_drug_positive_set.add(d)\n",
    "                    else:\n",
    "                        negs.append(q)\n",
    "                        problem1_drug_domain_pairs.add((m,d))\n",
    "                        problem1_pdq_triples.add((p,d,q))\n",
    "                        problem1_domain_set.add(m)\n",
    "                        problem1_drug_set.add(d)\n",
    "                        dataset1_protein_negative_set.add(q)\n",
    "                        dataset1_drug_negative_set.add(d)\n",
    "                else:\n",
    "                    unk.append(q)\n",
    "            if (type(p) == float):\n",
    "                print(\"error-p:\", p)\n",
    "            if (type(m) == float):\n",
    "                print(\"error-m:\", m)\n",
    "            if (type(d) == float):\n",
    "                print(\"error-d:\", d)                \n",
    "            row_str= \",\".join ([p,m,d,str(len(pos)),str(len(negs)),str(len(unk)),\";\".join(pos), \";\".join(negs), \";\".join(unk)])+\"\\n\"\n",
    "            csv_report_str += row_str\n",
    "            \n",
    "with open(\"outputs/problem1_10_30.csv\",\"w\") as outf:\n",
    "    outf.writelines(csv_report_str)\n",
    "\n",
    "Q_pos = dict()\n",
    "Q_neg = dict()\n",
    "for dom,dd in problem1_drug_domain_pairs:\n",
    "    for prot in  proteinswith[dom]:\n",
    "        if (prot, dd) in interact:\n",
    "            if interact[(prot,dd)]:\n",
    "                if (dom,dd) in Q_pos:\n",
    "                    Q_pos[(dom,dd)].add(prot)\n",
    "                else:\n",
    "                    Q_pos[(dom,dd)] = set([prot])\n",
    "            else:\n",
    "                if (dom,dd) in Q_neg:\n",
    "                    Q_neg[(dom,dd)].add(prot)\n",
    "                else:\n",
    "                    Q_neg[(dom,dd)] = set([prot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Conflicting Cases: rc1\n",
    "There are unreasonable cases in our dataset where a single domain protein (with our definition) interacts with a drug but another single domain protein with same domain doesn't interact. This can happen for different reasons.\n",
    "1. There is an error in the dataset in one of the two cases.\n",
    "2. These measurements are done in different conditions on the same (or very similar) proteins for example the pH or temperature are different. \n",
    "2. these two proteins though sharing same domain have some difference in the sequenc that causes them to show very different affinity to the same drug.\n",
    "\n",
    "In this experiment, we want to remove such cases to see how many drug-domain pairs involving how many domains) will remain in the dataset. This will be stored in `problem1_drug_domain_pairs_rc` rc stands for removed conflicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem1_drug_domain_pairs_rc1 = set()\n",
    "for dom,dd in problem1_drug_domain_pairs:\n",
    "    valid_entry = True\n",
    "    for q in Q_neg[(dom,dd)]:\n",
    "        if check_single_domain(q):\n",
    "            valid_entry = False\n",
    "    if valid_entry:\n",
    "        problem1_drug_domain_pairs_rc1.add((dom,dd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdq_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(problem1_drug_domain_pairs_rc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PF00001',\n",
       " 'PF00067',\n",
       " 'PF00089',\n",
       " 'PF00135',\n",
       " 'PF00186',\n",
       " 'PF00194',\n",
       " 'PF00303',\n",
       " 'PF00962',\n",
       " 'PF02931'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([dom for (dom,drug) in problem1_drug_domain_pairs_rc1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Conflicting Cases: rc2\n",
    "In the second way of removing coflict which is more strict, we assume that proteins that have same arrangement of domain/non-domain segments are equal. Meaning, we find the doman segments and also non-domain segements of length more than 30 residues and encode the protein based on arrangement of these segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_encoding(prot):\n",
    "    p_dict = pfam_record_dict(prot)\n",
    "    p_seq  = p_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "    p_len  = len (p_seq)\n",
    "    on_domain =[False]*p_len\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    if type(p_domains) != list:\n",
    "        p_domains =[p_domains]\n",
    "    last_end = 0\n",
    "    segments = []\n",
    "    for dom in p_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        begin = int(dom[\"location\"][\"@start\"])\n",
    "        end = int(dom[\"location\"][\"@end\"])\n",
    "        if begin-1-last_end > blank_length_threshold:\n",
    "            segments+= [\"B\",acc]  \n",
    "        else:\n",
    "            segments+= [acc]\n",
    "        last_end = end\n",
    "    if p_len-end > blank_length_threshold:\n",
    "        segments+= [\"B\"]\n",
    "    return \"_\".join(segments)\n",
    "\n",
    "problem1_drug_domain_pairs_rc2 = set()\n",
    "\n",
    "for dom,dd in problem1_drug_domain_pairs:\n",
    "    valid_entry = True\n",
    "    for p in Q_pos[(dom,dd)]:\n",
    "        for q in Q_neg[(dom,dd)]:\n",
    "            if get_segment_encoding(p)== get_segment_encoding(q):\n",
    "                valid_entry = False\n",
    "    if valid_entry:\n",
    "        problem1_drug_domain_pairs_rc2.add((dom,dd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(prot):\n",
    "    p_dict = pfam_record_dict(prot)\n",
    "    p_seq  = p_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "    p_len  = len (p_seq)\n",
    "    on_domain =[False]*p_len\n",
    "    p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "    if type(p_domains) != list:\n",
    "        p_domains =[p_domains]\n",
    "    last_end = 0\n",
    "    segments = []\n",
    "    for dom in p_domains:\n",
    "        acc = dom[\"@accession\"]\n",
    "        begin = int(dom[\"location\"][\"@start\"])\n",
    "        end = int(dom[\"location\"][\"@end\"])\n",
    "        if begin-1-last_end > blank_length_threshold:\n",
    "            segments+= [\"B[\"+str(last_end+1)+\"-\"+str(begin-1)+\"]\"]\n",
    "            segments+= [acc+\"[\"+str(begin)+\"-\"+str(end)+\"]\"]            \n",
    "        else:\n",
    "            segments+= [acc+\"[\"+str(begin)+\"-\"+str(end)+\"]\"]\n",
    "        last_end = end\n",
    "    if p_len-end > blank_length_threshold:\n",
    "        segments+= [\"B[\"+str(end+1)+\"-\"+str(p_len)+\"]\"]\n",
    "    return \"_\".join(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PF00067[31-488]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_segment_encoding(\"P20813\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(problem1_drug_domain_pairs_rc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PF00001',\n",
       " 'PF00067',\n",
       " 'PF00089',\n",
       " 'PF00135',\n",
       " 'PF00186',\n",
       " 'PF00194',\n",
       " 'PF00303',\n",
       " 'PF00962',\n",
       " 'PF02931'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([dom for (dom,drug) in problem1_drug_domain_pairs_rc2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Createing report of found examples\n",
    "\n",
    "since we learned that even with imposing these restirctions, we have close to one thoasand examples left, we generate the report based on these examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xmltodict\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "\n",
    "class StringConverter(dict):\n",
    "    def __contains__(self, item):\n",
    "        return True\n",
    "    def __getitem__(self, item):\n",
    "        return str\n",
    "    def get(self, default=None):\n",
    "        return str\n",
    "\n",
    "shared_dom_col= (0,0.608,0.62,0.8)\n",
    "shared_dom_col_pos= (0,0.608,0.2,0.8)\n",
    "shared_dom_col_neg = (0.62,0.1,0.1,0.8)\n",
    "other_dom_col= (0.6,0.6,0.6,0.8)\n",
    "\n",
    "    \n",
    "def visualize(pos_set, neg_set,drug,shared_domain,issingdom,fig_name):\n",
    "    pos_set  = list (pos_set)\n",
    "    neg_set = list(neg_set)\n",
    "    height = len(pos_set)+len(neg_set)\n",
    "    fig = plt.figure(figsize=[8, height])\n",
    "    ax = fig.add_subplot(111)\n",
    "    max_seq_len = 0\n",
    "    top_to_bottom_idx = 0\n",
    "    y_labels = []\n",
    "    y_ticks = []\n",
    "    \n",
    "    for i in range (len(pos_set)):\n",
    "        vert_idx = height-top_to_bottom_idx\n",
    "        p = pos_set[i]\n",
    "        y_labels += [p]\n",
    "        y_ticks += [vert_idx]       \n",
    "        p_path = domain_data_dir+p+\".xml\"\n",
    "        with open(p_path) as pf:\n",
    "            p_dict = xmltodict.parse(pf.read())\n",
    "        p_seq  = p_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "        p_len  = len (p_seq)\n",
    "        max_seq_len = max(max_seq_len, p_len)\n",
    "        ax.hlines(vert_idx, 0, p_len, linewidth=2, color=\"grey\")\n",
    "        if (issingdom[p]):\n",
    "            ax.scatter([0,p_len],[vert_idx,vert_idx],s=100,c = \"k\")\n",
    "        p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "        if type(p_domains) != list:\n",
    "            p_domains =[p_domains]\n",
    "        for dom in p_domains:\n",
    "            acc = dom[\"@accession\"]\n",
    "            # type = dom[\"@type\"]\n",
    "            begin = int(dom[\"location\"][\"@start\"])\n",
    "            end = int(dom[\"location\"][\"@end\"])\n",
    "            #if pfam_A\n",
    "            if acc==shared_domain:\n",
    "                col = shared_dom_col_pos\n",
    "            else:\n",
    "                col = other_dom_col\n",
    "            ax.hlines(vert_idx, begin, end, linewidth=10, color=col)\n",
    "        top_to_bottom_idx +=1\n",
    "        \n",
    "        \n",
    "    for i in range (len(neg_set)):\n",
    "        vert_idx = height-top_to_bottom_idx\n",
    "        q = neg_set[i]\n",
    "        y_labels += [q]\n",
    "        y_ticks += [vert_idx]       \n",
    "        q_path = domain_data_dir + q + \".xml\"\n",
    "        with open(q_path) as qf:\n",
    "            q_dict = xmltodict.parse(qf.read())\n",
    "        q_seq = q_dict[\"pfam\"][\"entry\"][\"sequence\"][\"#text\"]\n",
    "        q_len = len(q_seq)\n",
    "        max_seq_len = max(max_seq_len,q_len)\n",
    "        ax.hlines(vert_idx, 0, q_len, linewidth=2, color=\"grey\")\n",
    "        q_domains = q_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "        if (issingdom[q]):\n",
    "            ax.scatter([0,q_len],[vert_idx,vert_idx],s=100,c = \"k\")\n",
    "        p_domains = p_dict[\"pfam\"][\"entry\"][\"matches\"][\"match\"]\n",
    "        if type(q_domains) != list:\n",
    "            q_domains =[q_domains]\n",
    "        for dom in q_domains:\n",
    "            acc = dom[\"@accession\"]\n",
    "            # type = dom[\"@type\"]\n",
    "            begin = int(dom[\"location\"][\"@start\"])\n",
    "            end = int(dom[\"location\"][\"@end\"])\n",
    "            # if pfam_A\n",
    "            if acc == shared_domain:\n",
    "                col = shared_dom_col_neg\n",
    "            else:\n",
    "                col = other_dom_col\n",
    "            ax.hlines(vert_idx, begin, end, linewidth=10, color=col)\n",
    "        top_to_bottom_idx +=1\n",
    "        \n",
    "    h_rng = float(max_seq_len)\n",
    "    h_margin = h_rng/10\n",
    "    ax.set_xlim(-h_margin, h_rng+h_margin)\n",
    "    ax.set_ylim(0.5, height+0.5)\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    fig.savefig(fig_name)\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "\n",
    "useful_cols_bindingdb = [\"Ki (nM)\",\"Kd (nM)\",\"IC50 (nM)\",\"EC50 (nM)\",\"kon (M-1-s-1)\",\"koff (s-1)\",\"pH\",\"Temp (C)\"]\n",
    "useful_cols_uniprot = [\"Entry\",\t\"Status\",\"Proteomes\",\"Entry name\",\"Organism\",\"Fragment\",\"Length\"]\n",
    "mdfile = \"# Potential examples for problem 1:\\n\"\n",
    "\n",
    "\n",
    "prot_info_df = pandas.read_csv(\"temp/unique_uniprot_info.tab\",sep= \"\\t\")\n",
    "prot_row_idx   = dict()\n",
    "for index, row in prot_info_df.iterrows():\n",
    "    pid = row[\"yourlist:M202103015C475328CEF75220C360D524E9D456CE1638CDK\"]\n",
    "    prot_row_idx[pid] = index\n",
    "    \n",
    "\n",
    "if not os.path.exists(\"outputs/problem_1_examples\"):\n",
    "    os.mkdir(\"outputs/problem_1_examples\")    \n",
    "for (dom,dd) in problem1_drug_domain_pairs:\n",
    "    mdfile += \"## domain_drug: \"+dom+\"_\"+dd+\"\\n\\n\"\n",
    "    mdfile += \"### Positives\\n\\n\"\n",
    "    row_idxs = [prot_row_idx[p] for p in Q_pos[dom,dd]]\n",
    "    pos_rows = prot_info_df.loc[row_idxs , useful_cols_uniprot]\n",
    "    mdfile += pos_rows.to_markdown(index = False)+\"\\n\\n\"\n",
    "    mdfile += \"### Negatives\\n\\n\"\n",
    "    row_idxs = [prot_row_idx[p] for p in Q_neg[dom,dd]]\n",
    "    neg_rows = prot_info_df.loc[row_idxs , useful_cols_uniprot]\n",
    "    mdfile += neg_rows.to_markdown(index = False)+\"\\n\\n\"\n",
    "    fig_name =\"outputs/problem_1_examples/\"+dom+\"_\"+dd+\".svg\"\n",
    "    visualize(Q_pos[(dom,dd)], Q_neg[(dom,dd)],dd,dom,issingledom,fig_name)\n",
    "    mdfile += \"![](\"+dom+\"_\"+dd+\".svg)\\n\\n\"\n",
    "\n",
    "\n",
    "\n",
    "with open(\"outputs/problem_1_examples/doc.md\", \"w\") as outf:\n",
    "    outf.writelines(mdfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfile = \"# Potential examples for problem 1:\\n\"\n",
    "\n",
    "if not os.path.exists(\"outputs/problem_1_examples_rc2\"):\n",
    "    os.mkdir(\"outputs/problem_1_examples_rc2\")    \n",
    "for (dom,dd) in problem1_drug_domain_pairs_rc2:\n",
    "    mdfile += \"## domain_drug: \"+dom+\"_\"+dd+\"\\n\\n\"\n",
    "    mdfile += \"### Positives\\n\\n\"\n",
    "    row_idxs = [prot_row_idx[p] for p in Q_pos[dom,dd]]\n",
    "    pos_rows = prot_info_df.loc[row_idxs , useful_cols_uniprot]\n",
    "    mdfile += pos_rows.to_markdown(index = False)+\"\\n\\n\"\n",
    "    mdfile += \"### Negatives\\n\\n\"\n",
    "    row_idxs = [prot_row_idx[p] for p in Q_neg[dom,dd]]\n",
    "    neg_rows = prot_info_df.loc[row_idxs , useful_cols_uniprot]\n",
    "    mdfile += neg_rows.to_markdown(index = False)+\"\\n\\n\"\n",
    "    fig_name =\"outputs/problem_1_examples_rc2/\"+dom+\"_\"+dd+\".svg\"\n",
    "    visualize(Q_pos[(dom,dd)], Q_neg[(dom,dd)],dd,dom,issingledom,fig_name)\n",
    "    mdfile += \"![](\"+dom+\"_\"+dd+\".svg)\\n\\n\"\n",
    "\n",
    "\n",
    "\n",
    "with open(\"outputs/problem_1_examples_rc2/doc.md\", \"w\") as outf:\n",
    "    outf.writelines(mdfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building dataset2\n",
    "in dataset1, we had positive pair (p,d), negative pair (q,d), where p is single domain and q shares a domain with p. In dataset2, we want to extend this dataset to include all negative (q,d)s and all negative (p,e). which means negatives that have a drug or protein in common with a postive pair in dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_proteinextended_negatives  = set()\n",
    "dataset2_drugextended_negatives = set()\n",
    "dataset2_proteinextended_positives  = set()\n",
    "dataset2_drugextended_positives = set()\n",
    "\n",
    "for (pp,dd) in interact:\n",
    "    inter = interact[(pp,dd)]\n",
    "    if pp in dataset1_protein_positive_set:\n",
    "        if not inter:\n",
    "            dataset2_proteinextended_negatives.add((pp,dd))          \n",
    "    if pp in dataset1_protein_negative_set:\n",
    "        if inter:\n",
    "            dataset2_proteinextended_positives.add((pp,dd)) \n",
    "    if dd in dataset1_drug_positive_set:\n",
    "        if not inter:\n",
    "            dataset2_drugextended_negatives.add((pp,dd))   \n",
    "    if dd in dataset1_drug_negative_set:\n",
    "        if inter:\n",
    "            dataset2_drugextended_positives.add((pp,dd))  \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2_drugextended_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5246"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2_proteinextended_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(dataset2_drugextended_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29312"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2_proteinextended_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_negatives  = dataset2_drugextended_negatives.union(dataset2_proteinextended_negatives).difference(dataset1_drug_prtein_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4896"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_positives  = dataset2_drugextended_positives.union(dataset2_proteinextended_positives).difference(dataset1_drug_prtein_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13536"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redundancy erduced cases\n",
    "in this case, if we observe that some of the proteins in positive and in negatives have same layout of domains non-domain regions, we remove those from the negatives that ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_all  = [(a,b) for (a,b) in interact if not interact[(a,b)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14015"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
